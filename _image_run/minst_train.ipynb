{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfb7dc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 93600\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import argparse\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "# 检查并移除 Jupyter 传递的参数\n",
    "if any('--f=' in arg for arg in sys.argv):\n",
    "    # 移除包含 '--f=' 的所有参数\n",
    "    sys.argv = [arg for arg in sys.argv if not arg.startswith('--f=')]\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description=\"Train a Mixture-of-Experts model.\")\n",
    "    parser.add_argument(\"--epochs\", type=int, default=200, help=\"Number of epochs to train.\")\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=128, help=\"Batch size for training.\")\n",
    "    parser.add_argument(\"--input_size\", type=int, default=10, help=\"Input size for the moe.\")\n",
    "    parser.add_argument(\"--num_experts\", type=int, default=2, help=\"Number of experts.\")\n",
    "    parser.add_argument(\"--hidden_size\", type=int, default=10, help=\"Hidden size for the moe.\")\n",
    "    parser.add_argument(\"--depth\", type=int, default=10, help=\"Depth of the experts.\")\n",
    "    parser.add_argument(\"--output_size\", type=int, default=10, help=\"Output size for the experts.\")\n",
    "    parser.add_argument(\"--activation\", type=str, default=\"tanh\", help=\"Activation function for the moe.\")\n",
    "    parser.add_argument(\"--k\", type=int, default=1, help=\"Top-k experts to use.\")\n",
    "    parser.add_argument(\"--loss_coef\", type=float, default=1e-2, help=\"Coefficient for the loss.\")\n",
    "    parser.add_argument(\"--smooth_steps\",type=int,default=1,help=\"number of steps for smooth mode\")\n",
    "    parser.add_argument(\"--smooth_lb\",type=int,default=200,help=\"number lower bound of steps for smooth mode\")\n",
    "    parser.add_argument(\"--seed\",type=int,default=1234) #1234\n",
    "    return parser.parse_args()\n",
    "args=parse_args()\n",
    "torch.manual_seed(args.seed)\n",
    "iteration= (60000 // args.batch_size) * args.epochs\n",
    "print(\"iteration:\",iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05d21520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在下载/加载 MNIST 训练数据集...\n",
      "数据集加载完成。\n",
      "\n",
      "--- 第一批数据结果 ---\n",
      "图片张量形状 (Batch, C, H, W): torch.Size([4, 1, 28, 28])\n",
      "标签张量形状 (Batch): torch.Size([4])\n",
      "\n",
      "--- 图像 1 ---\n",
      "  标签: 6\n",
      "  部分像素值 (前5x5):\n",
      "tensor([[-0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242]])\n",
      "--------------------\n",
      "--- 图像 2 ---\n",
      "  标签: 6\n",
      "  部分像素值 (前5x5):\n",
      "tensor([[-0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242]])\n",
      "--------------------\n",
      "--- 图像 3 ---\n",
      "  标签: 3\n",
      "  部分像素值 (前5x5):\n",
      "tensor([[-0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242]])\n",
      "--------------------\n",
      "--- 图像 4 ---\n",
      "  标签: 8\n",
      "  部分像素值 (前5x5):\n",
      "tensor([[-0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242]])\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt # 用于可视化，可选\n",
    "\n",
    "# 1. 定义数据预处理步骤\n",
    "# 转换为 Tensor，并进行标准化（这是深度学习的标准步骤）\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # MNIST的均值和标准差，用于将像素值归一化到 [-1, 1] 左右\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# 2. 下载并加载数据集\n",
    "# root='.' 表示下载到当前文件夹\n",
    "# train=True 表示下载训练集 (共60000张)\n",
    "# download=True 表示如果本地没有，则下载\n",
    "print(\"正在下载/加载 MNIST 训练数据集...\")\n",
    "train_dataset = torchvision.datasets.MNIST(root='/home/zhy/Zhou/mixture_of_experts/_image_run/MINST/', \n",
    "                                           train=True, \n",
    "                                           transform=transform, \n",
    "                                           download=True)\n",
    "print(\"数据集加载完成。\")\n",
    "\n",
    "# 3. 使用 DataLoader 载入数据\n",
    "# 设置一个较小的 batch_size 方便查看结果\n",
    "batch_size = 4\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "# 4. 取出并打印第一批数据\n",
    "# 迭代器next()方法取出第一批数据\n",
    "data_iter = iter(train_loader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "print(\"\\n--- 第一批数据结果 ---\")\n",
    "print(f\"图片张量形状 (Batch, C, H, W): {images.shape}\")\n",
    "print(f\"标签张量形状 (Batch): {labels.shape}\\n\")\n",
    "\n",
    "# 5. 打印前4张图片的信息\n",
    "for i in range(batch_size):\n",
    "    print(f\"--- 图像 {i+1} ---\")\n",
    "    \n",
    "    # 打印标签\n",
    "    print(f\"  标签: {labels[i].item()}\")\n",
    "    \n",
    "    # 打印部分像素值 (张量切片)\n",
    "    # 形状是 (1, 28, 28)，这里打印第0通道的前5行5列的像素值\n",
    "    print(\"  部分像素值 (前5x5):\")\n",
    "    print(images[i, 0, :5, :5])\n",
    "    print(\"-\" * 20)\n",
    "# （接上面的代码，在第5步之后运行）\n",
    "fig, axes = plt.subplots(1, batch_size, figsize=(10, 3))\n",
    "for i in range(batch_size):\n",
    "    # 移除标准化并转为Numpy数组\n",
    "    img = images[i].numpy().transpose((1, 2, 0)) # 将(C, H, W)转为(H, W, C)\n",
    "    \n",
    "    # 因为图像是归一化过的，这里需要简单的反归一化来正确显示\n",
    "    # 仅为了显示效果，我们直接裁剪到有效范围\n",
    "    axes[i].imshow(img.squeeze(), cmap='gray') \n",
    "    axes[i].set_title(f\"Label: {labels[i].item()}\")\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7751b15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用的设备: cuda:7\n",
      "=== Trainable parameters ===\n",
      "Total trainable params: 12994\n",
      "\n",
      "---  模型结构 ---\n",
      "MoE_vision(\n",
      "  (activation): ReLU()\n",
      "  (trans_layer): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (moe): ModuleList(\n",
      "    (0): MoE(\n",
      "      (experts): ModuleList(\n",
      "        (0): Expert(\n",
      "          (activation): ReLU()\n",
      "          (net): ModuleList(\n",
      "            (0-1): 2 x Linear(in_features=10, out_features=10, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (gating_network): Gate_fcnn(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=10, out_features=1, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=1, out_features=1, bias=True)\n",
      "        )\n",
      "        (noisy): Linear(in_features=10, out_features=1, bias=True)\n",
      "        (softplus): Softplus(beta=1.0, threshold=20.0)\n",
      "      )\n",
      "    )\n",
      "    (1-10): 10 x MoE(\n",
      "      (experts): ModuleList(\n",
      "        (0-1): 2 x Expert(\n",
      "          (activation): ReLU()\n",
      "          (net): ModuleList(\n",
      "            (0-1): 2 x Linear(in_features=10, out_features=10, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (gating_network): Gate_fcnn(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=10, out_features=2, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=2, out_features=2, bias=True)\n",
      "        )\n",
      "        (noisy): Linear(in_features=10, out_features=2, bias=True)\n",
      "        (softplus): Softplus(beta=1.0, threshold=20.0)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "输入尺寸: torch.Size([64, 1, 28, 28])\n",
      "输出尺寸: torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from moe import *\n",
    "device = torch.device(\"cuda:7\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用的设备: {device}\")\n",
    "net = MoE_vision(args.input_size, args.num_experts, args.hidden_size, args.depth, args.output_size, args.k, args.loss_coef,activation=nn.ReLU())\n",
    "# 打印模型结构\n",
    "print(\"---  模型结构 ---\")\n",
    "print(net)\n",
    "\n",
    "# 检查输入/输出尺寸\n",
    "# 假设批量大小为 64，输入是 (64, 1, 28, 28)\n",
    "input_tensor = torch.randn(64, 1, 28, 28) \n",
    "output , loss= net(input_tensor)\n",
    "print(f\"\\n输入尺寸: {input_tensor.shape}\")\n",
    "print(f\"输出尺寸: {output.shape}\") \n",
    "# 预期输出: torch.Size([64, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8526eb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Trainable parameters ===\n",
      "Total trainable params: 12994\n",
      "\n",
      "\n",
      "--- 开始训练 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhy/anaconda3/envs/env-zqh/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1,   100] loss: 1.721, aux_loss: 0.000\n",
      "[   1,   200] loss: 1.410, aux_loss: 0.000\n",
      "[   1,   300] loss: 1.576, aux_loss: 0.000\n",
      "[   1,   400] loss: 1.585, aux_loss: 0.000\n",
      "[   1,   500] loss: 1.659, aux_loss: 0.000\n",
      "[   1,   600] loss: 1.894, aux_loss: 0.000\n",
      "[   1,   700] loss: 1.817, aux_loss: 0.000\n",
      "[   1,   800] loss: 1.764, aux_loss: 0.000\n",
      "[   1,   900] loss: 1.730, aux_loss: 0.000\n",
      "[   2,   100] loss: 1.709, aux_loss: 0.000\n",
      "[   2,   200] loss: 1.685, aux_loss: 0.000\n",
      "[   2,   300] loss: 1.672, aux_loss: 0.000\n",
      "[   2,   400] loss: 1.813, aux_loss: 0.000\n",
      "[   2,   500] loss: 1.861, aux_loss: 0.000\n",
      "[   2,   600] loss: 1.773, aux_loss: 0.000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "# 假设 LeNet5 类已定义 (使用上一个回答中的代码)\n",
    "\n",
    "# --- 0. 环境准备：设备、数据加载 ---\n",
    "\n",
    "# 检查是否有GPU可用\n",
    "\n",
    "net = MoE_vision(args.input_size, args.num_experts, args.hidden_size, args.depth, args.output_size, args.k, args.loss_coef,activation=nn.ReLU()).to(device)\n",
    "\n",
    "# 数据预处理（与之前相同）\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# 重新加载训练集和测试集 (下载/加载)\n",
    "train_dataset = torchvision.datasets.MNIST(root='/home/zhy/Zhou/mixture_of_experts/_image_run/MINST/', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='/home/zhy/Zhou/mixture_of_experts/_image_run/MINST/', train=False, transform=transform, download=True)\n",
    "\n",
    "# 定义超参数\n",
    "BATCH_SIZE = 64 # LeNet通常可以使用较大的Batch Size\n",
    "epochs = 60 # 沿用您最初设定的epochs\n",
    "\n",
    "# 数据加载器\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "# --- 1. 模型、优化器和损失函数设置 ---\n",
    "\n",
    "# 实例化模型并移动到指定设备\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30, 45], gamma=0.1)\n",
    "\n",
    "\n",
    "# --- 2. 训练主循环 ---\n",
    "print(\"\\n--- 开始训练 ---\")\n",
    "\n",
    "\n",
    "step_count=args.smooth_steps\n",
    "\n",
    "for epoch in range(args.epochs):  # loop over the dataset multiple times\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    running_aux_loss = 0.0\n",
    "    scheduler.step()\n",
    "    \n",
    "    step_count -=1\n",
    "    for j in range(len(net.moe)):\n",
    "        if net.moe[j].smooth and step_count<=0:\n",
    "            net.moe[j].smoothing(epoch,args.smooth_lb)\n",
    "            step_count=args.smooth_steps\n",
    "        elif step_count<=0 :\n",
    "            net.moe[j].smoothing(epoch,args.smooth_lb)\n",
    "            step_count=args.smooth_steps\n",
    "\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        # inputs, labels = data\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "\n",
    "        # outputs, aux_loss= MoE(inputs)\n",
    "        outputs ,auxloss= net(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # total_loss =loss+ aux_loss\n",
    "        total_loss =loss\n",
    "\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        # running_aux_loss += aux_loss.item()\n",
    "        \n",
    "        if i % 100== 99:    # print every 100 mini-batches\n",
    "            print(f'[{epoch + 1:4d}, {i + 1:5d}] loss: {running_loss / 100:.3f}, aux_loss: {running_aux_loss/100:.3f}')\n",
    "            running_loss = 0.0\n",
    "            running_aux_loss = 0.0\n",
    "\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "\n",
    "# 保存训练好的模型（可选）\n",
    "PATH = '/home/zhy/Zhou/mixture_of_experts/_image_run/saved_cnn/mnist_lenet5.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41081992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "在 10000 张测试图片上的准确率: 99.30 %\n"
     ]
    }
   ],
   "source": [
    "net =  MoE_vision(args.input_size, args.num_experts, args.hidden_size, args.depth, args.output_size, args.k, args.loss_coef,activation=nn.ReLU()).to(device)\n",
    "\n",
    "net.load_state_dict(torch.load(PATH, weights_only=True))\n",
    "# 运行评估函数（可选，但推荐）\n",
    "def evaluate_model():\n",
    "    net.eval() # 设置模型为评估模式\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad(): # 评估时不需要计算梯度\n",
    "        for data in test_loader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1) # 获取预测结果\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'\\n在 10000 张测试图片上的准确率: {100 * correct / total:.2f} %')\n",
    "\n",
    "evaluate_model()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-zqh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

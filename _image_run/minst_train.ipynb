{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05d21520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在下载/加载 MNIST 训练数据集...\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to /home/zhy/Zhou/mixture_of_experts/_image_run/MINST/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:02<00:00, 4.78MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/zhy/Zhou/mixture_of_experts/_image_run/MINST/MNIST/raw/train-images-idx3-ubyte.gz to /home/zhy/Zhou/mixture_of_experts/_image_run/MINST/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [Errno 110] Connection timed out>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to /home/zhy/Zhou/mixture_of_experts/_image_run/MINST/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 36.4kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/zhy/Zhou/mixture_of_experts/_image_run/MINST/MNIST/raw/train-labels-idx1-ubyte.gz to /home/zhy/Zhou/mixture_of_experts/_image_run/MINST/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [Errno 110] Connection timed out>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to /home/zhy/Zhou/mixture_of_experts/_image_run/MINST/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.18MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/zhy/Zhou/mixture_of_experts/_image_run/MINST/MNIST/raw/t10k-images-idx3-ubyte.gz to /home/zhy/Zhou/mixture_of_experts/_image_run/MINST/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [Errno 110] Connection timed out>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to /home/zhy/Zhou/mixture_of_experts/_image_run/MINST/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 1.61MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/zhy/Zhou/mixture_of_experts/_image_run/MINST/MNIST/raw/t10k-labels-idx1-ubyte.gz to /home/zhy/Zhou/mixture_of_experts/_image_run/MINST/MNIST/raw\n",
      "\n",
      "数据集加载完成。\n",
      "\n",
      "--- 第一批数据结果 ---\n",
      "图片张量形状 (Batch, C, H, W): torch.Size([4, 1, 28, 28])\n",
      "标签张量形状 (Batch): torch.Size([4])\n",
      "\n",
      "--- 图像 1 ---\n",
      "  标签: 0\n",
      "  部分像素值 (前5x5):\n",
      "tensor([[-0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242]])\n",
      "--------------------\n",
      "--- 图像 2 ---\n",
      "  标签: 1\n",
      "  部分像素值 (前5x5):\n",
      "tensor([[-0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242]])\n",
      "--------------------\n",
      "--- 图像 3 ---\n",
      "  标签: 0\n",
      "  部分像素值 (前5x5):\n",
      "tensor([[-0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242]])\n",
      "--------------------\n",
      "--- 图像 4 ---\n",
      "  标签: 5\n",
      "  部分像素值 (前5x5):\n",
      "tensor([[-0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242]])\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt # 用于可视化，可选\n",
    "\n",
    "# 1. 定义数据预处理步骤\n",
    "# 转换为 Tensor，并进行标准化（这是深度学习的标准步骤）\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # MNIST的均值和标准差，用于将像素值归一化到 [-1, 1] 左右\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# 2. 下载并加载数据集\n",
    "# root='.' 表示下载到当前文件夹\n",
    "# train=True 表示下载训练集 (共60000张)\n",
    "# download=True 表示如果本地没有，则下载\n",
    "print(\"正在下载/加载 MNIST 训练数据集...\")\n",
    "train_dataset = torchvision.datasets.MNIST(root='/home/zhy/Zhou/mixture_of_experts/_image_run/MINST/', \n",
    "                                           train=True, \n",
    "                                           transform=transform, \n",
    "                                           download=True)\n",
    "print(\"数据集加载完成。\")\n",
    "\n",
    "# 3. 使用 DataLoader 载入数据\n",
    "# 设置一个较小的 batch_size 方便查看结果\n",
    "batch_size = 4\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "# 4. 取出并打印第一批数据\n",
    "# 迭代器next()方法取出第一批数据\n",
    "data_iter = iter(train_loader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "print(\"\\n--- 第一批数据结果 ---\")\n",
    "print(f\"图片张量形状 (Batch, C, H, W): {images.shape}\")\n",
    "print(f\"标签张量形状 (Batch): {labels.shape}\\n\")\n",
    "\n",
    "# 5. 打印前4张图片的信息\n",
    "for i in range(batch_size):\n",
    "    print(f\"--- 图像 {i+1} ---\")\n",
    "    \n",
    "    # 打印标签\n",
    "    print(f\"  标签: {labels[i].item()}\")\n",
    "    \n",
    "    # 打印部分像素值 (张量切片)\n",
    "    # 形状是 (1, 28, 28)，这里打印第0通道的前5行5列的像素值\n",
    "    print(\"  部分像素值 (前5x5):\")\n",
    "    print(images[i, 0, :5, :5])\n",
    "    print(\"-\" * 20)\n",
    "# （接上面的代码，在第5步之后运行）\n",
    "fig, axes = plt.subplots(1, batch_size, figsize=(10, 3))\n",
    "for i in range(batch_size):\n",
    "    # 移除标准化并转为Numpy数组\n",
    "    img = images[i].numpy().transpose((1, 2, 0)) # 将(C, H, W)转为(H, W, C)\n",
    "    \n",
    "    # 因为图像是归一化过的，这里需要简单的反归一化来正确显示\n",
    "    # 仅为了显示效果，我们直接裁剪到有效范围\n",
    "    axes[i].imshow(img.squeeze(), cmap='gray') \n",
    "    axes[i].set_title(f\"Label: {labels[i].item()}\")\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7751b15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- LeNet-5 模型结构 ---\n",
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "输入尺寸: torch.Size([64, 1, 28, 28])\n",
      "输出尺寸: torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    经典的 LeNet-5 架构，针对 28x28 灰度图 (MNIST) 进行了调整。\n",
    "    \n",
    "    原始 LeNet-5 的输入是 32x32，这里使用 28x28，\n",
    "    但整体的 Conv -> Pool -> Conv -> Pool -> FC 结构保持不变。\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # 1. 卷积层 C1\n",
    "        # 输入: (1, 28, 28)\n",
    "        # 输出: (6, 28, 28)  (6个 5x5 卷积核, padding=2 保持尺寸)\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2)\n",
    "        # 激活函数: 使用 ReLU 取代 sigmoid/tanh，以加速训练\n",
    "        \n",
    "        # 2. 池化层 S2 (平均池化)\n",
    "        # 输入: (6, 28, 28)\n",
    "        # 输出: (6, 14, 14)  (2x2 池化，步长为 2)\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # 3. 卷积层 C3\n",
    "        # 输入: (6, 14, 14)\n",
    "        # 输出: (16, 10, 10) (16个 5x5 卷积核, 无 padding)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        \n",
    "        # 4. 池化层 S4 (平均池化)\n",
    "        # 输入: (16, 10, 10)\n",
    "        # 输出: (16, 5, 5)   (2x2 池化，步长为 2)\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # 计算进入全连接层时的展平尺寸: 16 * 5 * 5 = 400\n",
    "        \n",
    "        # 5. 全连接层 F5\n",
    "        # 输入: 16 * 5 * 5 = 400\n",
    "        # 输出: 120\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        \n",
    "        # 6. 全连接层 F6\n",
    "        # 输入: 120\n",
    "        # 输出: 84\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        \n",
    "        # 7. 输出层 Output\n",
    "        # 输入: 84\n",
    "        # 输出: num_classes (10)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # C1: Conv -> ReLU -> Pool\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        \n",
    "        # C3: Conv -> ReLU -> Pool\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        \n",
    "        # 展平操作 (Flatten): (Batch, 16, 5, 5) -> (Batch, 400)\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        \n",
    "        # F5: FC -> ReLU\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        # F6: FC -> ReLU\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        # Output: FC\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        # 注意: 训练时通常直接输出 logits，不在这里加 softmax\n",
    "        return x\n",
    "\n",
    "# 实例化 LeNet-5 模型\n",
    "net = Net(num_classes=10)\n",
    "\n",
    "# 打印模型结构\n",
    "print(\"--- LeNet-5 模型结构 ---\")\n",
    "print(net)\n",
    "\n",
    "# 检查输入/输出尺寸\n",
    "# 假设批量大小为 64，输入是 (64, 1, 28, 28)\n",
    "input_tensor = torch.randn(64, 1, 28, 28) \n",
    "output = net(input_tensor)\n",
    "print(f\"\\n输入尺寸: {input_tensor.shape}\")\n",
    "print(f\"输出尺寸: {output.shape}\") \n",
    "# 预期输出: torch.Size([64, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8526eb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用的设备: cuda:7\n",
      "\n",
      "--- 开始训练 ---\n",
      "[ 1,   190] loss: 1.195\n",
      "[ 1,   380] loss: 0.253\n",
      "[ 1,   570] loss: 0.185\n",
      "[ 1,   760] loss: 0.173\n",
      "Epoch 1 结束, 当前学习率 (LR): 0.100000\n",
      "[ 2,   190] loss: 0.134\n",
      "[ 2,   380] loss: 0.122\n",
      "[ 2,   570] loss: 0.112\n",
      "[ 2,   760] loss: 0.107\n",
      "Epoch 2 结束, 当前学习率 (LR): 0.100000\n",
      "[ 3,   190] loss: 0.097\n",
      "[ 3,   380] loss: 0.102\n",
      "[ 3,   570] loss: 0.102\n",
      "[ 3,   760] loss: 0.091\n",
      "Epoch 3 结束, 当前学习率 (LR): 0.100000\n",
      "[ 4,   190] loss: 0.086\n",
      "[ 4,   380] loss: 0.096\n",
      "[ 4,   570] loss: 0.100\n",
      "[ 4,   760] loss: 0.094\n",
      "Epoch 4 结束, 当前学习率 (LR): 0.100000\n",
      "[ 5,   190] loss: 0.082\n",
      "[ 5,   380] loss: 0.077\n",
      "[ 5,   570] loss: 0.084\n",
      "[ 5,   760] loss: 0.090\n",
      "Epoch 5 结束, 当前学习率 (LR): 0.100000\n",
      "[ 6,   190] loss: 0.081\n",
      "[ 6,   380] loss: 0.095\n",
      "[ 6,   570] loss: 0.081\n",
      "[ 6,   760] loss: 0.079\n",
      "Epoch 6 结束, 当前学习率 (LR): 0.100000\n",
      "[ 7,   190] loss: 0.079\n",
      "[ 7,   380] loss: 0.084\n",
      "[ 7,   570] loss: 0.091\n",
      "[ 7,   760] loss: 0.074\n",
      "Epoch 7 结束, 当前学习率 (LR): 0.100000\n",
      "[ 8,   190] loss: 0.076\n",
      "[ 8,   380] loss: 0.073\n",
      "[ 8,   570] loss: 0.075\n",
      "[ 8,   760] loss: 0.071\n",
      "Epoch 8 结束, 当前学习率 (LR): 0.100000\n",
      "[ 9,   190] loss: 0.072\n",
      "[ 9,   380] loss: 0.080\n",
      "[ 9,   570] loss: 0.085\n",
      "[ 9,   760] loss: 0.084\n",
      "Epoch 9 结束, 当前学习率 (LR): 0.100000\n",
      "[10,   190] loss: 0.073\n",
      "[10,   380] loss: 0.084\n",
      "[10,   570] loss: 0.069\n",
      "[10,   760] loss: 0.075\n",
      "Epoch 10 结束, 当前学习率 (LR): 0.100000\n",
      "[11,   190] loss: 0.068\n",
      "[11,   380] loss: 0.076\n",
      "[11,   570] loss: 0.074\n",
      "[11,   760] loss: 0.076\n",
      "Epoch 11 结束, 当前学习率 (LR): 0.100000\n",
      "[12,   190] loss: 0.062\n",
      "[12,   380] loss: 0.084\n",
      "[12,   570] loss: 0.072\n",
      "[12,   760] loss: 0.071\n",
      "Epoch 12 结束, 当前学习率 (LR): 0.100000\n",
      "[13,   190] loss: 0.073\n",
      "[13,   380] loss: 0.056\n",
      "[13,   570] loss: 0.070\n",
      "[13,   760] loss: 0.070\n",
      "Epoch 13 结束, 当前学习率 (LR): 0.100000\n",
      "[14,   190] loss: 0.064\n",
      "[14,   380] loss: 0.065\n",
      "[14,   570] loss: 0.079\n",
      "[14,   760] loss: 0.072\n",
      "Epoch 14 结束, 当前学习率 (LR): 0.100000\n",
      "[15,   190] loss: 0.056\n",
      "[15,   380] loss: 0.069\n",
      "[15,   570] loss: 0.068\n",
      "[15,   760] loss: 0.083\n",
      "Epoch 15 结束, 当前学习率 (LR): 0.100000\n",
      "[16,   190] loss: 0.080\n",
      "[16,   380] loss: 0.068\n",
      "[16,   570] loss: 0.068\n",
      "[16,   760] loss: 0.069\n",
      "Epoch 16 结束, 当前学习率 (LR): 0.100000\n",
      "[17,   190] loss: 0.058\n",
      "[17,   380] loss: 0.075\n",
      "[17,   570] loss: 0.073\n",
      "[17,   760] loss: 0.063\n",
      "Epoch 17 结束, 当前学习率 (LR): 0.100000\n",
      "[18,   190] loss: 0.069\n",
      "[18,   380] loss: 0.069\n",
      "[18,   570] loss: 0.067\n",
      "[18,   760] loss: 0.066\n",
      "Epoch 18 结束, 当前学习率 (LR): 0.100000\n",
      "[19,   190] loss: 0.062\n",
      "[19,   380] loss: 0.068\n",
      "[19,   570] loss: 0.070\n",
      "[19,   760] loss: 0.069\n",
      "Epoch 19 结束, 当前学习率 (LR): 0.100000\n",
      "[20,   190] loss: 0.065\n",
      "[20,   380] loss: 0.058\n",
      "[20,   570] loss: 0.066\n",
      "[20,   760] loss: 0.073\n",
      "Epoch 20 结束, 当前学习率 (LR): 0.100000\n",
      "[21,   190] loss: 0.059\n",
      "[21,   380] loss: 0.074\n",
      "[21,   570] loss: 0.062\n",
      "[21,   760] loss: 0.071\n",
      "Epoch 21 结束, 当前学习率 (LR): 0.100000\n",
      "[22,   190] loss: 0.064\n",
      "[22,   380] loss: 0.062\n",
      "[22,   570] loss: 0.063\n",
      "[22,   760] loss: 0.071\n",
      "Epoch 22 结束, 当前学习率 (LR): 0.100000\n",
      "[23,   190] loss: 0.053\n",
      "[23,   380] loss: 0.073\n",
      "[23,   570] loss: 0.057\n",
      "[23,   760] loss: 0.074\n",
      "Epoch 23 结束, 当前学习率 (LR): 0.100000\n",
      "[24,   190] loss: 0.061\n",
      "[24,   380] loss: 0.058\n",
      "[24,   570] loss: 0.071\n",
      "[24,   760] loss: 0.063\n",
      "Epoch 24 结束, 当前学习率 (LR): 0.100000\n",
      "[25,   190] loss: 0.059\n",
      "[25,   380] loss: 0.060\n",
      "[25,   570] loss: 0.071\n",
      "[25,   760] loss: 0.057\n",
      "Epoch 25 结束, 当前学习率 (LR): 0.100000\n",
      "[26,   190] loss: 0.056\n",
      "[26,   380] loss: 0.069\n",
      "[26,   570] loss: 0.068\n",
      "[26,   760] loss: 0.060\n",
      "Epoch 26 结束, 当前学习率 (LR): 0.100000\n",
      "[27,   190] loss: 0.060\n",
      "[27,   380] loss: 0.053\n",
      "[27,   570] loss: 0.073\n",
      "[27,   760] loss: 0.059\n",
      "Epoch 27 结束, 当前学习率 (LR): 0.100000\n",
      "[28,   190] loss: 0.057\n",
      "[28,   380] loss: 0.054\n",
      "[28,   570] loss: 0.074\n",
      "[28,   760] loss: 0.063\n",
      "Epoch 28 结束, 当前学习率 (LR): 0.100000\n",
      "[29,   190] loss: 0.054\n",
      "[29,   380] loss: 0.052\n",
      "[29,   570] loss: 0.057\n",
      "[29,   760] loss: 0.068\n",
      "Epoch 29 结束, 当前学习率 (LR): 0.100000\n",
      "[30,   190] loss: 0.057\n",
      "[30,   380] loss: 0.072\n",
      "[30,   570] loss: 0.056\n",
      "[30,   760] loss: 0.067\n",
      "Epoch 30 结束, 当前学习率 (LR): 0.010000\n",
      "[31,   190] loss: 0.033\n",
      "[31,   380] loss: 0.028\n",
      "[31,   570] loss: 0.023\n",
      "[31,   760] loss: 0.022\n",
      "Epoch 31 结束, 当前学习率 (LR): 0.010000\n",
      "[32,   190] loss: 0.018\n",
      "[32,   380] loss: 0.018\n",
      "[32,   570] loss: 0.015\n",
      "[32,   760] loss: 0.019\n",
      "Epoch 32 结束, 当前学习率 (LR): 0.010000\n",
      "[33,   190] loss: 0.015\n",
      "[33,   380] loss: 0.016\n",
      "[33,   570] loss: 0.013\n",
      "[33,   760] loss: 0.015\n",
      "Epoch 33 结束, 当前学习率 (LR): 0.010000\n",
      "[34,   190] loss: 0.016\n",
      "[34,   380] loss: 0.014\n",
      "[34,   570] loss: 0.011\n",
      "[34,   760] loss: 0.016\n",
      "Epoch 34 结束, 当前学习率 (LR): 0.010000\n",
      "[35,   190] loss: 0.011\n",
      "[35,   380] loss: 0.014\n",
      "[35,   570] loss: 0.016\n",
      "[35,   760] loss: 0.013\n",
      "Epoch 35 结束, 当前学习率 (LR): 0.010000\n",
      "[36,   190] loss: 0.011\n",
      "[36,   380] loss: 0.014\n",
      "[36,   570] loss: 0.011\n",
      "[36,   760] loss: 0.012\n",
      "Epoch 36 结束, 当前学习率 (LR): 0.010000\n",
      "[37,   190] loss: 0.011\n",
      "[37,   380] loss: 0.014\n",
      "[37,   570] loss: 0.013\n",
      "[37,   760] loss: 0.012\n",
      "Epoch 37 结束, 当前学习率 (LR): 0.010000\n",
      "[38,   190] loss: 0.011\n",
      "[38,   380] loss: 0.010\n",
      "[38,   570] loss: 0.013\n",
      "[38,   760] loss: 0.012\n",
      "Epoch 38 结束, 当前学习率 (LR): 0.010000\n",
      "[39,   190] loss: 0.012\n",
      "[39,   380] loss: 0.011\n",
      "[39,   570] loss: 0.014\n",
      "[39,   760] loss: 0.011\n",
      "Epoch 39 结束, 当前学习率 (LR): 0.010000\n",
      "[40,   190] loss: 0.013\n",
      "[40,   380] loss: 0.010\n",
      "[40,   570] loss: 0.009\n",
      "[40,   760] loss: 0.010\n",
      "Epoch 40 结束, 当前学习率 (LR): 0.010000\n",
      "[41,   190] loss: 0.009\n",
      "[41,   380] loss: 0.012\n",
      "[41,   570] loss: 0.012\n",
      "[41,   760] loss: 0.011\n",
      "Epoch 41 结束, 当前学习率 (LR): 0.010000\n",
      "[42,   190] loss: 0.009\n",
      "[42,   380] loss: 0.010\n",
      "[42,   570] loss: 0.011\n",
      "[42,   760] loss: 0.009\n",
      "Epoch 42 结束, 当前学习率 (LR): 0.010000\n",
      "[43,   190] loss: 0.010\n",
      "[43,   380] loss: 0.009\n",
      "[43,   570] loss: 0.011\n",
      "[43,   760] loss: 0.011\n",
      "Epoch 43 结束, 当前学习率 (LR): 0.010000\n",
      "[44,   190] loss: 0.010\n",
      "[44,   380] loss: 0.011\n",
      "[44,   570] loss: 0.011\n",
      "[44,   760] loss: 0.011\n",
      "Epoch 44 结束, 当前学习率 (LR): 0.010000\n",
      "[45,   190] loss: 0.007\n",
      "[45,   380] loss: 0.009\n",
      "[45,   570] loss: 0.012\n",
      "[45,   760] loss: 0.011\n",
      "Epoch 45 结束, 当前学习率 (LR): 0.001000\n",
      "[46,   190] loss: 0.008\n",
      "[46,   380] loss: 0.008\n",
      "[46,   570] loss: 0.009\n",
      "[46,   760] loss: 0.007\n",
      "Epoch 46 结束, 当前学习率 (LR): 0.001000\n",
      "[47,   190] loss: 0.007\n",
      "[47,   380] loss: 0.008\n",
      "[47,   570] loss: 0.006\n",
      "[47,   760] loss: 0.008\n",
      "Epoch 47 结束, 当前学习率 (LR): 0.001000\n",
      "[48,   190] loss: 0.007\n",
      "[48,   380] loss: 0.006\n",
      "[48,   570] loss: 0.006\n",
      "[48,   760] loss: 0.009\n",
      "Epoch 48 结束, 当前学习率 (LR): 0.001000\n",
      "[49,   190] loss: 0.007\n",
      "[49,   380] loss: 0.006\n",
      "[49,   570] loss: 0.009\n",
      "[49,   760] loss: 0.007\n",
      "Epoch 49 结束, 当前学习率 (LR): 0.001000\n",
      "[50,   190] loss: 0.007\n",
      "[50,   380] loss: 0.006\n",
      "[50,   570] loss: 0.008\n",
      "[50,   760] loss: 0.008\n",
      "Epoch 50 结束, 当前学习率 (LR): 0.001000\n",
      "[51,   190] loss: 0.008\n",
      "[51,   380] loss: 0.006\n",
      "[51,   570] loss: 0.008\n",
      "[51,   760] loss: 0.007\n",
      "Epoch 51 结束, 当前学习率 (LR): 0.001000\n",
      "[52,   190] loss: 0.007\n",
      "[52,   380] loss: 0.007\n",
      "[52,   570] loss: 0.007\n",
      "[52,   760] loss: 0.006\n",
      "Epoch 52 结束, 当前学习率 (LR): 0.001000\n",
      "[53,   190] loss: 0.005\n",
      "[53,   380] loss: 0.009\n",
      "[53,   570] loss: 0.007\n",
      "[53,   760] loss: 0.007\n",
      "Epoch 53 结束, 当前学习率 (LR): 0.001000\n",
      "[54,   190] loss: 0.007\n",
      "[54,   380] loss: 0.007\n",
      "[54,   570] loss: 0.007\n",
      "[54,   760] loss: 0.007\n",
      "Epoch 54 结束, 当前学习率 (LR): 0.001000\n",
      "[55,   190] loss: 0.009\n",
      "[55,   380] loss: 0.006\n",
      "[55,   570] loss: 0.008\n",
      "[55,   760] loss: 0.007\n",
      "Epoch 55 结束, 当前学习率 (LR): 0.001000\n",
      "[56,   190] loss: 0.006\n",
      "[56,   380] loss: 0.006\n",
      "[56,   570] loss: 0.009\n",
      "[56,   760] loss: 0.008\n",
      "Epoch 56 结束, 当前学习率 (LR): 0.001000\n",
      "[57,   190] loss: 0.006\n",
      "[57,   380] loss: 0.005\n",
      "[57,   570] loss: 0.010\n",
      "[57,   760] loss: 0.008\n",
      "Epoch 57 结束, 当前学习率 (LR): 0.001000\n",
      "[58,   190] loss: 0.006\n",
      "[58,   380] loss: 0.007\n",
      "[58,   570] loss: 0.008\n",
      "[58,   760] loss: 0.006\n",
      "Epoch 58 结束, 当前学习率 (LR): 0.001000\n",
      "[59,   190] loss: 0.007\n",
      "[59,   380] loss: 0.007\n",
      "[59,   570] loss: 0.006\n",
      "[59,   760] loss: 0.008\n",
      "Epoch 59 结束, 当前学习率 (LR): 0.001000\n",
      "[60,   190] loss: 0.007\n",
      "[60,   380] loss: 0.008\n",
      "[60,   570] loss: 0.007\n",
      "[60,   760] loss: 0.007\n",
      "Epoch 60 结束, 当前学习率 (LR): 0.001000\n",
      "训练结束!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "# 假设 LeNet5 类已定义 (使用上一个回答中的代码)\n",
    "\n",
    "# --- 0. 环境准备：设备、数据加载 ---\n",
    "\n",
    "# 检查是否有GPU可用\n",
    "device = torch.device(\"cuda:7\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用的设备: {device}\")\n",
    "\n",
    "# 数据预处理（与之前相同）\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# 重新加载训练集和测试集 (下载/加载)\n",
    "train_dataset = torchvision.datasets.MNIST(root='/home/zhy/Zhou/mixture_of_experts/_image_run/MINST/', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='/home/zhy/Zhou/mixture_of_experts/_image_run/MINST/', train=False, transform=transform, download=True)\n",
    "\n",
    "# 定义超参数\n",
    "BATCH_SIZE = 64 # LeNet通常可以使用较大的Batch Size\n",
    "epochs = 60 # 沿用您最初设定的epochs\n",
    "\n",
    "# 数据加载器\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "# --- 1. 模型、优化器和损失函数设置 ---\n",
    "\n",
    "# 实例化模型并移动到指定设备\n",
    "net = Net(num_classes=10).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30, 45], gamma=0.1)\n",
    "\n",
    "\n",
    "# --- 2. 训练主循环 ---\n",
    "print(\"\\n--- 开始训练 ---\")\n",
    "\n",
    "for epoch in range(epochs):  # 循环训练 epochs 次\n",
    "    net.train() # 设置模型为训练模式\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # 遍历训练数据加载器中的所有批次\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # 获取输入数据和标签，并移动到设备上\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # 每隔 190 个 mini-batches 打印一次 Loss\n",
    "        # 您的数据集总共 60000/64 = 937.5 个 batch，所以 190 是一个很好的间隔\n",
    "        if i % 190 == 189: # 这里的 189 确保是第 190, 380, ... 个 batch 结束时打印\n",
    "            print(f'[{epoch + 1:2d}, {i + 1:5d}] loss: {running_loss / 190:.3f}')\n",
    "            running_loss = 0.0 # 清零累加器，开始统计下一个 190 batch 的平均 Loss\n",
    "\n",
    "    scheduler.step()\n",
    "    current_lr = scheduler.get_last_lr()[0]\n",
    "    print(f\"Epoch {epoch + 1} 结束, 当前学习率 (LR): {current_lr:.6f}\")\n",
    "\n",
    "print('训练结束!')\n",
    "\n",
    "\n",
    "\n",
    "# 保存训练好的模型（可选）\n",
    "PATH = '/home/zhy/Zhou/mixture_of_experts/_image_run/saved_cnn/mnist_lenet5.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41081992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "在 10000 张测试图片上的准确率: 99.30 %\n"
     ]
    }
   ],
   "source": [
    "net = Net(num_classes=10).to(device)\n",
    "net.load_state_dict(torch.load(PATH, weights_only=True))\n",
    "# 运行评估函数（可选，但推荐）\n",
    "def evaluate_model():\n",
    "    net.eval() # 设置模型为评估模式\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad(): # 评估时不需要计算梯度\n",
    "        for data in test_loader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1) # 获取预测结果\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'\\n在 10000 张测试图片上的准确率: {100 * correct / total:.2f} %')\n",
    "\n",
    "evaluate_model()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-zqh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

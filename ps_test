import torch
from torch import nn
import torch.optim as optimi
from tqdm.auto import tqdm
import argparse
import numpy as np
from functorch import make_functional, vmap
from moe_module.moe import MOE_modify_beta,MLP_Model, MOE_2expert
from moe_module.utils import parse_args, _init_data_dim1, get_optimizer, get_loss_fn, log_with_time,plot_dual_axis, plot_expert_useless_rank, get_activation\
    ,generate_data,save_model,gates_image,beta_image
from moe_module.epi_rank import epi_rank_mlp
from moe_module.tools import *
# download data
from torch.utils.data import DataLoader
from torch.autograd import grad
import matplotlib.pyplot as plt
import data.bg_gt as bg_gt
from torch.optim.lr_scheduler import StepLR

def parse_args():
    parser = argparse.ArgumentParser(description="Train a Mixture-of-Experts model.")
    parser.add_argument("--epochs", type=int, default=10, help="Number of training epochs.")
    parser.add_argument("--lr", type=float, default=2e-3, help="Learning rate.")
    parser.add_argument("--device", type=str, default="cuda:6" if torch.cuda.is_available() else "cpu", help="Device to train on.")    
    parser.add_argument("--input_size", type=int, default=2,help="Input size (funcion approximation x) ")
    parser.add_argument("--output_size", type=int, default=1,help="Output size (funcion approximation y=u(x)) ")
    parser.add_argument("--num_experts", type=int, default=2,help="Number of experts")
    parser.add_argument("--hidden_size", type=int, default=10,help="Hidden size of each expert")
    parser.add_argument("--depth", type=int, default=4,help="Depth of the MOE model")
    parser.add_argument("--lossfn", type=str, default="mse", help="Loss function.")
    parser.add_argument("--optim", type=str, default="adam")
    parser.add_argument("--opt_steps", type=int, default=8000)
    parser.add_argument("--activation", type=str, default="tanh", help="activation_function")
    parser.add_argument("--init_func", type=str, default="-sin(pi*x)", help="function")
    parser.add_argument("--x_interval", type=str, default="[-1,1]")
    parser.add_argument("--y_interval", type=str, default="[0,1]")
    parser.add_argument("--x_num_samples", type=int, default=200)
    parser.add_argument("--y_num_samples", type=int, default=100)
    parser.add_argument("--k", type=int, default=1,help="top-k selection")
    parser.add_argument("--loss_coef", type=float, default=1)
    parser.add_argument("--x_integral_sample", type=int, default=200, help="x_integral_sample")
    parser.add_argument("--y_integral_sample", type=int, default=200, help="t_integral_sample")
    parser.add_argument("--nu", type=float, default=0.01/np.pi,help="nu in equation u_t + u*u_x - nu*u_xx=0")
    parser.add_argument("--plt_r", type=int, default=-1)
    parser.add_argument("--epsilon", type=float, default=1e-3,help="epsilon for rank")
    parser.add_argument("--loss_coef_init", type=float, default=1)
    parser.add_argument("--loss_coef_bnd", type=float, default=1)
    parser.add_argument("--vtn",type=int,default=100)
    parser.add_argument("--vxn",type=int,default=100)
    parser.add_argument("--gt",type=torch.Tensor,default=None,help="ground truth")
    parser.add_argument("--X_test",type=torch.Tensor,default=None,help="test data")
    parser.add_argument("--lr_decay",type=float,default=0.996,help="lr decay")
    parser.add_argument("--lbfgs_steps",type=int,default=1000,help="number of steps for lbfgs")
    parser.add_argument("--seed",type=int,default=1234) #1234
    parser.add_argument("--smooth_steps",type=int,default=5,help="number of steps for smooth mode")
    parser.add_argument("--smooth_lb",type=int,default=0,help="number lower bound of steps for smooth mode")
    parser.add_argument("--x_integral_interval" ,type=str, default="[-0.3,0.3]")
    parser.add_argument("--y_integral_interval", type=str, default="[0,1]")
    return parser.parse_args()

def pde_residual(model, x_y, nu, moe_training=True):
    """
    u: model output
    x_t: tensor shape (N,2) with columns [x, t], requires_grad=True
    returns: residual r = u_t + u u_x - nu u_xx
    """
    x_y.requires_grad_(True)
    if moe_training:u, _ = model(x_y)
    else: u = model(x_y)
    g = grad(outputs=u,inputs=x_y,grad_outputs=torch.ones_like(u),create_graph=True,retain_graph=True)[0]                      # shape (N,2)
    u_x = g[:, 0:1]
    u_y = g[:, 1:2]

    # 二阶: u_xx = d/dx(u_x)
    u_xx = grad(
        outputs=u_x,inputs=x_y,grad_outputs=torch.ones_like(u_x),create_graph=True,retain_graph=True)[0][:, 0:1]
    u_yy = grad(
        outputs=u_y,inputs=x_y,grad_outputs=torch.ones_like(u_x),create_graph=True,retain_graph=True)[0][:, 1:2]

    r = u_xx+u_yy
    return r
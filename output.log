data_x shape: torch.Size([250, 1]),data_y shape: torch.Size([250, 1]) 
Step 1/10000 - loss: 2.41081526 -aux_loss: 0.00001301-rank: 8,[8, 7, 7]
Step 101/10000 - loss: 0.54904414 -aux_loss: 0.00002500-rank: 9,[11, 13, 14]
Step 201/10000 - loss: 0.50363204 -aux_loss: 0.00002650-rank: 10,[13, 14, 16]
Step 301/10000 - loss: 0.48167630 -aux_loss: 0.00002427-rank: 11,[12, 14, 17]
Step 401/10000 - loss: 0.49095210 -aux_loss: 0.00003417-rank: 10,[12, 15, 17]
Step 501/10000 - loss: 0.49388375 -aux_loss: 0.00003288-rank: 10,[13, 15, 17]
Step 601/10000 - loss: 0.48625719 -aux_loss: 0.00002052-rank: 9,[11, 14, 15]
Step 701/10000 - loss: 0.49333428 -aux_loss: 0.00004414-rank: 9,[11, 14, 15]
Step 801/10000 - loss: 0.48753488 -aux_loss: 0.00003641-rank: 9,[11, 14, 17]
Step 901/10000 - loss: 0.48800158 -aux_loss: 0.00004915-rank: 9,[11, 14, 17]
Step 1001/10000 - loss: 0.48045449 -aux_loss: 0.00007579-rank: 9,[11, 16, 18]
Step 1101/10000 - loss: 0.45694130 -aux_loss: 0.00009228-rank: 9,[13, 17, 22]
Step 1201/10000 - loss: 0.40623775 -aux_loss: 0.00025568-rank: 9,[14, 21, 26]
Step 1301/10000 - loss: 0.39392788 -aux_loss: 0.00027579-rank: 10,[17, 25, 31]
Step 1401/10000 - loss: 0.36160405 -aux_loss: 0.00034487-rank: 10,[17, 28, 35]
Step 1501/10000 - loss: 0.31022693 -aux_loss: 0.00047638-rank: 10,[19, 31, 39]
Step 1601/10000 - loss: 0.27476658 -aux_loss: 0.00061381-rank: 11,[21, 33, 41]
Step 1701/10000 - loss: 0.21985304 -aux_loss: 0.00059788-rank: 11,[23, 37, 44]
Step 1801/10000 - loss: 0.18330241 -aux_loss: 0.00057464-rank: 11,[25, 38, 47]
Step 1901/10000 - loss: 0.16461321 -aux_loss: 0.00068819-rank: 11,[26, 39, 47]
Step 2001/10000 - loss: 0.14863340 -aux_loss: 0.00074222-rank: 10,[27, 37, 46]
Step 2101/10000 - loss: 0.13440263 -aux_loss: 0.00083122-rank: 11,[28, 38, 46]
Step 2201/10000 - loss: 0.12680548 -aux_loss: 0.00088634-rank: 10,[29, 38, 47]
Step 2301/10000 - loss: 0.12182673 -aux_loss: 0.00096133-rank: 9,[29, 37, 47]
Step 2401/10000 - loss: 0.12076180 -aux_loss: 0.00094432-rank: 8,[27, 38, 47]
Step 2501/10000 - loss: 0.09733091 -aux_loss: 0.00101487-rank: 8,[28, 38, 47]
Step 2601/10000 - loss: 0.07119274 -aux_loss: 0.00116249-rank: 8,[28, 38, 46]
Step 2701/10000 - loss: 0.05670092 -aux_loss: 0.00134656-rank: 8,[29, 38, 46]
Step 2801/10000 - loss: 0.05012580 -aux_loss: 0.00153901-rank: 8,[29, 40, 47]
Step 2901/10000 - loss: 0.04689776 -aux_loss: 0.00161270-rank: 9,[31, 40, 47]
Step 3001/10000 - loss: 0.04162074 -aux_loss: 0.00179640-rank: 9,[30, 39, 48]
Step 3101/10000 - loss: 0.03061185 -aux_loss: 0.00207399-rank: 11,[33, 40, 48]
Step 3201/10000 - loss: 0.01004851 -aux_loss: 0.00249415-rank: 8,[32, 40, 48]
Step 3301/10000 - loss: 0.00269504 -aux_loss: 0.00237689-rank: 8,[33, 40, 47]
Step 3401/10000 - loss: 0.00206408 -aux_loss: 0.00212858-rank: 8,[33, 40, 47]
Step 3501/10000 - loss: 0.00156186 -aux_loss: 0.00194233-rank: 8,[33, 40, 46]
Step 3601/10000 - loss: 0.00258791 -aux_loss: 0.00168843-rank: 8,[32, 39, 46]
Step 3701/10000 - loss: 0.00116791 -aux_loss: 0.00168661-rank: 8,[31, 39, 47]
Step 3801/10000 - loss: 0.00149403 -aux_loss: 0.00157587-rank: 8,[31, 39, 47]
Step 3901/10000 - loss: 0.00288266 -aux_loss: 0.00157772-rank: 8,[31, 39, 47]
Step 4001/10000 - loss: 0.00252791 -aux_loss: 0.00156281-rank: 10,[32, 40, 47]
Step 4101/10000 - loss: 0.00104714 -aux_loss: 0.00146229-rank: 10,[32, 40, 47]
Step 4201/10000 - loss: 0.00182943 -aux_loss: 0.00146391-rank: 10,[32, 40, 47]
Step 4301/10000 - loss: 0.00103522 -aux_loss: 0.00148783-rank: 10,[32, 40, 47]
Step 4401/10000 - loss: 0.00691610 -aux_loss: 0.00145400-rank: 10,[31, 40, 46]
Step 4501/10000 - loss: 0.00123365 -aux_loss: 0.00142723-rank: 10,[31, 40, 46]
Step 4601/10000 - loss: 0.00111337 -aux_loss: 0.00135573-rank: 10,[31, 40, 46]
Step 4701/10000 - loss: 0.00179022 -aux_loss: 0.00142288-rank: 8,[30, 39, 46]
Step 4801/10000 - loss: 0.00219060 -aux_loss: 0.00146518-rank: 8,[30, 39, 46]
Step 4901/10000 - loss: 0.00114550 -aux_loss: 0.00147275-rank: 8,[30, 39, 46]
Step 5001/10000 - loss: 0.00141555 -aux_loss: 0.00144569-rank: 8,[30, 40, 46]
Step 5101/10000 - loss: 0.00348762 -aux_loss: 0.00147876-rank: 8,[30, 39, 46]
Step 5201/10000 - loss: 0.00133822 -aux_loss: 0.00144737-rank: 8,[29, 39, 46]
Step 5301/10000 - loss: 0.00189867 -aux_loss: 0.00159601-rank: 9,[30, 39, 46]
Step 5401/10000 - loss: 0.00257196 -aux_loss: 0.00150868-rank: 9,[30, 39, 46]
Step 5501/10000 - loss: 0.00092800 -aux_loss: 0.00147653-rank: 9,[30, 39, 45]
Step 5601/10000 - loss: 0.00300276 -aux_loss: 0.00157763-rank: 9,[29, 39, 46]
Step 5701/10000 - loss: 0.00212647 -aux_loss: 0.00157876-rank: 9,[29, 39, 46]
Step 5801/10000 - loss: 0.00124373 -aux_loss: 0.00152651-rank: 9,[30, 39, 46]
Step 5901/10000 - loss: 0.00304303 -aux_loss: 0.00157360-rank: 8,[28, 38, 45]
Step 6001/10000 - loss: 0.00109500 -aux_loss: 0.00162504-rank: 8,[28, 38, 45]
Step 6101/10000 - loss: 0.00108767 -aux_loss: 0.00153524-rank: 8,[27, 37, 45]
Step 6201/10000 - loss: 0.00333298 -aux_loss: 0.00152580-rank: 8,[27, 38, 45]
Step 6301/10000 - loss: 0.00159587 -aux_loss: 0.00152965-rank: 8,[27, 38, 45]
Step 6401/10000 - loss: 0.00105941 -aux_loss: 0.00156749-rank: 8,[27, 38, 44]
Step 6501/10000 - loss: 0.00070973 -aux_loss: 0.00154044-rank: 8,[27, 39, 44]
Step 6601/10000 - loss: 0.00099286 -aux_loss: 0.00156207-rank: 8,[27, 38, 44]
Step 6701/10000 - loss: 0.00302221 -aux_loss: 0.00157201-rank: 8,[27, 39, 44]
Step 6801/10000 - loss: 0.00150896 -aux_loss: 0.00151886-rank: 8,[27, 39, 45]
Step 6901/10000 - loss: 0.00240698 -aux_loss: 0.00152206-rank: 8,[27, 38, 44]
Step 7001/10000 - loss: 0.00177050 -aux_loss: 0.00151530-rank: 8,[27, 38, 44]
Step 7101/10000 - loss: 0.00072019 -aux_loss: 0.00154126-rank: 8,[27, 38, 44]
Step 7201/10000 - loss: 0.00109055 -aux_loss: 0.00151913-rank: 8,[27, 38, 44]
Step 7301/10000 - loss: 0.00117324 -aux_loss: 0.00149008-rank: 8,[27, 38, 44]
Step 7401/10000 - loss: 0.00077361 -aux_loss: 0.00154450-rank: 8,[27, 38, 44]
Step 7501/10000 - loss: 0.00102096 -aux_loss: 0.00151541-rank: 8,[27, 38, 44]
Step 7601/10000 - loss: 0.00128091 -aux_loss: 0.00152840-rank: 8,[27, 38, 44]
Step 7701/10000 - loss: 0.00067431 -aux_loss: 0.00153686-rank: 8,[27, 38, 44]
Step 7801/10000 - loss: 0.00164343 -aux_loss: 0.00150128-rank: 8,[27, 38, 44]
Step 7901/10000 - loss: 0.00144828 -aux_loss: 0.00150457-rank: 8,[27, 38, 44]
Step 8001/10000 - loss: 0.00257246 -aux_loss: 0.00152934-rank: 9,[27, 38, 44]
Step 8101/10000 - loss: 0.00191524 -aux_loss: 0.00151047-rank: 8,[27, 38, 44]
Step 8201/10000 - loss: 0.00106374 -aux_loss: 0.00151799-rank: 8,[27, 38, 44]
Step 8301/10000 - loss: 0.00064214 -aux_loss: 0.00148575-rank: 8,[27, 38, 44]
Step 8401/10000 - loss: 0.00211713 -aux_loss: 0.00150953-rank: 8,[27, 38, 44]
Step 8501/10000 - loss: 0.00140602 -aux_loss: 0.00152643-rank: 8,[27, 38, 44]
Step 8601/10000 - loss: 0.00129200 -aux_loss: 0.00153130-rank: 8,[27, 38, 44]
Step 8701/10000 - loss: 0.00187399 -aux_loss: 0.00152100-rank: 8,[27, 38, 44]
Step 8801/10000 - loss: 0.00180604 -aux_loss: 0.00151033-rank: 8,[27, 38, 44]
Step 8901/10000 - loss: 0.00074859 -aux_loss: 0.00152383-rank: 8,[27, 38, 44]
Step 9001/10000 - loss: 0.00122752 -aux_loss: 0.00152680-rank: 9,[27, 38, 44]
Step 9101/10000 - loss: 0.00106459 -aux_loss: 0.00151961-rank: 8,[26, 38, 44]
Step 9201/10000 - loss: 0.00118162 -aux_loss: 0.00149456-rank: 8,[26, 38, 43]
Step 9301/10000 - loss: 0.00114707 -aux_loss: 0.00151015-rank: 8,[27, 38, 43]
Step 9401/10000 - loss: 0.00124059 -aux_loss: 0.00151312-rank: 8,[26, 38, 43]
Step 9501/10000 - loss: 0.00168064 -aux_loss: 0.00151554-rank: 8,[27, 38, 43]
Step 9601/10000 - loss: 0.00258858 -aux_loss: 0.00150205-rank: 8,[27, 38, 43]
Step 9701/10000 - loss: 0.00145423 -aux_loss: 0.00151187-rank: 8,[27, 38, 43]
Step 9801/10000 - loss: 0.00158597 -aux_loss: 0.00150868-rank: 9,[26, 38, 43]
Step 9901/10000 - loss: 0.00127928 -aux_loss: 0.00150529-rank: 8,[26, 38, 43]
Step 10000/10000 - loss: 0.00101472 -aux_loss: 0.00152352-rank: 9,[27, 38, 43]
MoE_Model Evaluation Results - loss: 0.00121173, aux_loss: 0.00230608
Gates:
 tensor([[0.0000, 0.0000, 0.5821, 0.4179],
        [0.0000, 0.0000, 0.7095, 0.2905],
        [0.0000, 0.0000, 0.4575, 0.5425],
        [0.0000, 0.0000, 0.1557, 0.8443],
        [0.0000, 0.0590, 0.9410, 0.0000],
        [0.0000, 0.0000, 0.2704, 0.7296],
        [0.0814, 0.0000, 0.9186, 0.0000],
        [0.0000, 0.0000, 0.5413, 0.4587],
        [0.0000, 0.0000, 0.3285, 0.6715],
        [0.0000, 0.0000, 0.7614, 0.2386],
        [0.0000, 0.0000, 0.7872, 0.2128],
        [0.0000, 0.0000, 0.9000, 0.1000],
        [0.0000, 0.0615, 0.9385, 0.0000],
        [0.0000, 0.0000, 0.2134, 0.7866],
        [0.0000, 0.0000, 0.3458, 0.6542],
        [0.0000, 0.0000, 0.8914, 0.1086],
        [0.0698, 0.0000, 0.9302, 0.0000],
        [0.0000, 0.0000, 0.9065, 0.0935],
        [0.0653, 0.0000, 0.9347, 0.0000],
        [0.0808, 0.0000, 0.9192, 0.0000],
        [0.0000, 0.0000, 0.1752, 0.8248],
        [0.0000, 0.0000, 0.4306, 0.5694],
        [0.0000, 0.0000, 0.8439, 0.1561],
        [0.0000, 0.0000, 0.5033, 0.4967],
        [0.0676, 0.0000, 0.9324, 0.0000],
        [0.0843, 0.0000, 0.9157, 0.0000],
        [0.0000, 0.0530, 0.9470, 0.0000],
        [0.0000, 0.0000, 0.6311, 0.3689],
        [0.0000, 0.0000, 0.2497, 0.7503],
        [0.0000, 0.0000, 0.8868, 0.1132],
        [0.0000, 0.0000, 0.5280, 0.4720],
        [0.0000, 0.0577, 0.9423, 0.0000],
        [0.0000, 0.0000, 0.4757, 0.5243],
        [0.0000, 0.0000, 0.1710, 0.8290],
        [0.0000, 0.0000, 0.2938, 0.7062],
        [0.0000, 0.0577, 0.9423, 0.0000],
        [0.0000, 0.0000, 0.9143, 0.0857],
        [0.0000, 0.0000, 0.2170, 0.7830],
        [0.0000, 0.0000, 0.8391, 0.1609],
        [0.0000, 0.0000, 0.8568, 0.1432],
        [0.0000, 0.0000, 0.2478, 0.7522],
        [0.0000, 0.0000, 0.7670, 0.2330],
        [0.0000, 0.0636, 0.9364, 0.0000],
        [0.0000, 0.0000, 0.3300, 0.6700],
        [0.0842, 0.0000, 0.9158, 0.0000],
        [0.0000, 0.0609, 0.9391, 0.0000],
        [0.0000, 0.0000, 0.1713, 0.8287],
        [0.0000, 0.0000, 0.6569, 0.3431],
        [0.0766, 0.0000, 0.9234, 0.0000],
        [0.0000, 0.0000, 0.5516, 0.4484],
        [0.0000, 0.0000, 0.8615, 0.1385],
        [0.0000, 0.0549, 0.9451, 0.0000],
        [0.0000, 0.0000, 0.8214, 0.1786],
        [0.0000, 0.0000, 0.3572, 0.6428],
        [0.0000, 0.0000, 0.6647, 0.3353],
        [0.0000, 0.0000, 0.1554, 0.8446],
        [0.0000, 0.0000, 0.2565, 0.7435],
        [0.0000, 0.0000, 0.2760, 0.7240],
        [0.0000, 0.0000, 0.8275, 0.1725],
        [0.0000, 0.0528, 0.9472, 0.0000],
        [0.0000, 0.0000, 0.2066, 0.7934],
        [0.0000, 0.0000, 0.3818, 0.6182],
        [0.0000, 0.0000, 0.5447, 0.4553],
        [0.0000, 0.0000, 0.7454, 0.2546],
        [0.0000, 0.0000, 0.7083, 0.2917],
        [0.0000, 0.0000, 0.7693, 0.2307],
        [0.0000, 0.0000, 0.3277, 0.6723],
        [0.0842, 0.0000, 0.9158, 0.0000],
        [0.0000, 0.0000, 0.2573, 0.7427],
        [0.0000, 0.0000, 0.8881, 0.1119],
        [0.0000, 0.0000, 0.7376, 0.2624],
        [0.0000, 0.0000, 0.8937, 0.1063],
        [0.0000, 0.0000, 0.4992, 0.5008],
        [0.0000, 0.0000, 0.4248, 0.5752],
        [0.0767, 0.0000, 0.9233, 0.0000],
        [0.0000, 0.0000, 0.3806, 0.6194],
        [0.0000, 0.0000, 0.8017, 0.1983],
        [0.0000, 0.0000, 0.7391, 0.2609],
        [0.0000, 0.0000, 0.7191, 0.2809],
        [0.0000, 0.0586, 0.9414, 0.0000],
        [0.0000, 0.0000, 0.8572, 0.1428],
        [0.0000, 0.0000, 0.2194, 0.7806],
        [0.0000, 0.0615, 0.9385, 0.0000],
        [0.0000, 0.0000, 0.7283, 0.2717],
        [0.0000, 0.0000, 0.8697, 0.1303],
        [0.0000, 0.0000, 0.9095, 0.0905],
        [0.0000, 0.0000, 0.8379, 0.1621],
        [0.0000, 0.0000, 0.1659, 0.8341],
        [0.0000, 0.0000, 0.4423, 0.5577],
        [0.0000, 0.0000, 0.4105, 0.5895],
        [0.0000, 0.0000, 0.3872, 0.6128],
        [0.0000, 0.0540, 0.9460, 0.0000],
        [0.0000, 0.0000, 0.2506, 0.7494],
        [0.0000, 0.0000, 0.3427, 0.6573],
        [0.0000, 0.0000, 0.5812, 0.4188],
        [0.0000, 0.0000, 0.1981, 0.8019],
        [0.0000, 0.0000, 0.5556, 0.4444],
        [0.0000, 0.0000, 0.3595, 0.6405],
        [0.0000, 0.0000, 0.5817, 0.4183],
        [0.0000, 0.0000, 0.7779, 0.2221],
        [0.0000, 0.0000, 0.2605, 0.7395],
        [0.0000, 0.0000, 0.8949, 0.1051],
        [0.0000, 0.0584, 0.9416, 0.0000],
        [0.0000, 0.0000, 0.5866, 0.4134],
        [0.0655, 0.0000, 0.9345, 0.0000],
        [0.0000, 0.0000, 0.2659, 0.7341],
        [0.0000, 0.0000, 0.2788, 0.7212],
        [0.0000, 0.0000, 0.2578, 0.7422],
        [0.0000, 0.0000, 0.8028, 0.1972],
        [0.0000, 0.0000, 0.8462, 0.1538],
        [0.0000, 0.0000, 0.2111, 0.7889],
        [0.0000, 0.0000, 0.8932, 0.1068],
        [0.0000, 0.0000, 0.8093, 0.1907],
        [0.0000, 0.0000, 0.4658, 0.5342],
        [0.0000, 0.0000, 0.3698, 0.6302],
        [0.0000, 0.0000, 0.2846, 0.7154],
        [0.0000, 0.0527, 0.9473, 0.0000],
        [0.0000, 0.0000, 0.8881, 0.1119],
        [0.0000, 0.0000, 0.2028, 0.7972],
        [0.0000, 0.0000, 0.2142, 0.7858],
        [0.0000, 0.0000, 0.3880, 0.6120],
        [0.0000, 0.0000, 0.8953, 0.1047],
        [0.0000, 0.0000, 0.7569, 0.2431],
        [0.0000, 0.0000, 0.3598, 0.6402],
        [0.0000, 0.0000, 0.2968, 0.7032],
        [0.0000, 0.0000, 0.7336, 0.2664],
        [0.0000, 0.0000, 0.3159, 0.6841],
        [0.0000, 0.0000, 0.9122, 0.0878],
        [0.0760, 0.0000, 0.9240, 0.0000],
        [0.0000, 0.0000, 0.8736, 0.1264],
        [0.0739, 0.0000, 0.9261, 0.0000],
        [0.0000, 0.0000, 0.7260, 0.2740],
        [0.0833, 0.0000, 0.9167, 0.0000],
        [0.0694, 0.0000, 0.9306, 0.0000],
        [0.0000, 0.0000, 0.3078, 0.6922],
        [0.0000, 0.0611, 0.9389, 0.0000],
        [0.0000, 0.0000, 0.1570, 0.8430],
        [0.0000, 0.0000, 0.9060, 0.0940],
        [0.0000, 0.0539, 0.9461, 0.0000],
        [0.0000, 0.0000, 0.8941, 0.1059],
        [0.0697, 0.0000, 0.9303, 0.0000],
        [0.0000, 0.0000, 0.8955, 0.1045],
        [0.0850, 0.0000, 0.9150, 0.0000],
        [0.0000, 0.0000, 0.7666, 0.2334],
        [0.0000, 0.0627, 0.9373, 0.0000],
        [0.0658, 0.0000, 0.9342, 0.0000],
        [0.0000, 0.0000, 0.4283, 0.5717],
        [0.0752, 0.0000, 0.9248, 0.0000],
        [0.0752, 0.0000, 0.9248, 0.0000],
        [0.0000, 0.0000, 0.5539, 0.4461],
        [0.0743, 0.0000, 0.9257, 0.0000],
        [0.0769, 0.0000, 0.9231, 0.0000],
        [0.0000, 0.0000, 0.2362, 0.7638],
        [0.0000, 0.0000, 0.6957, 0.3043],
        [0.0000, 0.0000, 0.2929, 0.7071],
        [0.0000, 0.0000, 0.2880, 0.7120],
        [0.0000, 0.0000, 0.3899, 0.6101],
        [0.0000, 0.0000, 0.1662, 0.8338],
        [0.0000, 0.0000, 0.8660, 0.1340],
        [0.0000, 0.0000, 0.8945, 0.1055],
        [0.0000, 0.0000, 0.6329, 0.3671],
        [0.0667, 0.0000, 0.9333, 0.0000],
        [0.0000, 0.0000, 0.5419, 0.4581],
        [0.0000, 0.0000, 0.1780, 0.8220],
        [0.0696, 0.0000, 0.9304, 0.0000],
        [0.0000, 0.0000, 0.8782, 0.1218],
        [0.0000, 0.0000, 0.8206, 0.1794],
        [0.0000, 0.0000, 0.9094, 0.0906],
        [0.0000, 0.0000, 0.3443, 0.6557],
        [0.0000, 0.0000, 0.4109, 0.5891],
        [0.0000, 0.0000, 0.4685, 0.5315],
        [0.0000, 0.0000, 0.3737, 0.6263],
        [0.0000, 0.0000, 0.6664, 0.3336],
        [0.0000, 0.0000, 0.7562, 0.2438],
        [0.0825, 0.0000, 0.9175, 0.0000],
        [0.0000, 0.0000, 0.1658, 0.8342],
        [0.0732, 0.0000, 0.9268, 0.0000],
        [0.0708, 0.0000, 0.9292, 0.0000],
        [0.0000, 0.0000, 0.7707, 0.2293],
        [0.0000, 0.0000, 0.3198, 0.6802],
        [0.0000, 0.0571, 0.9429, 0.0000],
        [0.0000, 0.0000, 0.4578, 0.5422],
        [0.0000, 0.0000, 0.1755, 0.8245],
        [0.0000, 0.0000, 0.6887, 0.3113],
        [0.0000, 0.0000, 0.8204, 0.1796],
        [0.0000, 0.0000, 0.2795, 0.7205],
        [0.0000, 0.0000, 0.7471, 0.2529],
        [0.0701, 0.0000, 0.9299, 0.0000],
        [0.0000, 0.0000, 0.7931, 0.2069],
        [0.0000, 0.0000, 0.6509, 0.3491],
        [0.0673, 0.0000, 0.9327, 0.0000],
        [0.0000, 0.0000, 0.4408, 0.5592],
        [0.0809, 0.0000, 0.9191, 0.0000],
        [0.0000, 0.0000, 0.8310, 0.1690],
        [0.0000, 0.0621, 0.9379, 0.0000],
        [0.0000, 0.0000, 0.7975, 0.2025],
        [0.0000, 0.0558, 0.9442, 0.0000],
        [0.0000, 0.0000, 0.8430, 0.1570],
        [0.0000, 0.0633, 0.9367, 0.0000],
        [0.0000, 0.0000, 0.7681, 0.2319],
        [0.0000, 0.0000, 0.8528, 0.1472],
        [0.0000, 0.0568, 0.9432, 0.0000],
        [0.0000, 0.0000, 0.8764, 0.1236],
        [0.0000, 0.0000, 0.9021, 0.0979],
        [0.0699, 0.0000, 0.9301, 0.0000],
        [0.0000, 0.0000, 0.3122, 0.6878],
        [0.0000, 0.0000, 0.1585, 0.8415],
        [0.0000, 0.0000, 0.3286, 0.6714],
        [0.0000, 0.0000, 0.2550, 0.7450],
        [0.0721, 0.0000, 0.9279, 0.0000],
        [0.0000, 0.0000, 0.3126, 0.6874],
        [0.0000, 0.0000, 0.8938, 0.1062],
        [0.0641, 0.0000, 0.9359, 0.0000],
        [0.0000, 0.0000, 0.2879, 0.7121],
        [0.0676, 0.0000, 0.9324, 0.0000],
        [0.0000, 0.0000, 0.6705, 0.3295],
        [0.0000, 0.0526, 0.9474, 0.0000],
        [0.0000, 0.0000, 0.3450, 0.6550],
        [0.0000, 0.0000, 0.4187, 0.5813],
        [0.0000, 0.0000, 0.3965, 0.6035],
        [0.0000, 0.0000, 0.8821, 0.1179],
        [0.0782, 0.0000, 0.9218, 0.0000],
        [0.0000, 0.0608, 0.9392, 0.0000],
        [0.0000, 0.0000, 0.7398, 0.2602],
        [0.0000, 0.0000, 0.7563, 0.2437],
        [0.0000, 0.0000, 0.3580, 0.6420],
        [0.0000, 0.0000, 0.8827, 0.1173],
        [0.0000, 0.0000, 0.7118, 0.2882],
        [0.0000, 0.0000, 0.7059, 0.2941],
        [0.0659, 0.0000, 0.9341, 0.0000],
        [0.0000, 0.0000, 0.2191, 0.7809],
        [0.0000, 0.0000, 0.8819, 0.1181],
        [0.0681, 0.0000, 0.9319, 0.0000],
        [0.0000, 0.0000, 0.2245, 0.7755],
        [0.0000, 0.0636, 0.9364, 0.0000],
        [0.0000, 0.0000, 0.8445, 0.1555],
        [0.0000, 0.0000, 0.8655, 0.1345],
        [0.0000, 0.0000, 0.2971, 0.7029],
        [0.0000, 0.0000, 0.8270, 0.1730],
        [0.0000, 0.0000, 0.8773, 0.1227],
        [0.0000, 0.0000, 0.7602, 0.2398],
        [0.0000, 0.0000, 0.3690, 0.6309],
        [0.0000, 0.0000, 0.1946, 0.8054],
        [0.0000, 0.0000, 0.6030, 0.3970],
        [0.0806, 0.0000, 0.9194, 0.0000],
        [0.0000, 0.0551, 0.9449, 0.0000],
        [0.0000, 0.0000, 0.2917, 0.7083],
        [0.0000, 0.0000, 0.7977, 0.2023],
        [0.0000, 0.0000, 0.7204, 0.2796],
        [0.0000, 0.0000, 0.4697, 0.5303]], device='cuda:7',
       grad_fn=<ScatterBackward0>)
Step 1/10000 - loss: 2.31901771 -rank: [2, 3, 4, 5, 5]
Step 101/10000 - loss: 0.54403002 -rank: [2, 4, 6, 6, 8]
Step 201/10000 - loss: 0.49204258 -rank: [2, 4, 5, 6, 8]
Step 301/10000 - loss: 0.48890634 -rank: [2, 4, 5, 6, 8]
Step 401/10000 - loss: 0.48810946 -rank: [2, 4, 5, 6, 8]
Step 501/10000 - loss: 0.48733080 -rank: [2, 4, 5, 6, 9]
Step 601/10000 - loss: 0.48040785 -rank: [2, 4, 5, 7, 10]
Step 701/10000 - loss: 0.40888109 -rank: [2, 4, 6, 10, 17]
Step 801/10000 - loss: 0.37775720 -rank: [2, 4, 6, 11, 22]
Step 901/10000 - loss: 0.29346851 -rank: [2, 4, 6, 15, 29]
Step 1001/10000 - loss: 0.21048366 -rank: [2, 4, 7, 18, 33]
Step 1101/10000 - loss: 0.19180976 -rank: [2, 4, 7, 19, 34]
Step 1201/10000 - loss: 0.17628785 -rank: [2, 4, 8, 21, 33]
Step 1301/10000 - loss: 0.15466688 -rank: [2, 4, 8, 24, 35]
Step 1401/10000 - loss: 0.14345639 -rank: [2, 4, 8, 24, 36]
Step 1501/10000 - loss: 0.13191259 -rank: [2, 4, 8, 25, 35]
Step 1601/10000 - loss: 0.12354321 -rank: [2, 4, 9, 27, 35]
Step 1701/10000 - loss: 0.09557043 -rank: [2, 4, 10, 28, 37]
Step 1801/10000 - loss: 0.08409505 -rank: [2, 4, 10, 28, 37]
Step 1901/10000 - loss: 0.07579892 -rank: [2, 5, 11, 28, 37]
Step 2001/10000 - loss: 0.06680369 -rank: [2, 5, 11, 29, 35]
Step 2101/10000 - loss: 0.05835417 -rank: [2, 5, 12, 29, 35]
Step 2201/10000 - loss: 0.04602691 -rank: [2, 5, 12, 28, 36]
Step 2301/10000 - loss: 0.01397652 -rank: [2, 5, 13, 28, 38]
Step 2401/10000 - loss: 0.00327506 -rank: [2, 5, 14, 28, 38]
Step 2501/10000 - loss: 0.00124865 -rank: [2, 5, 14, 28, 38]
Step 2601/10000 - loss: 0.00096234 -rank: [2, 5, 14, 27, 37]
Step 2701/10000 - loss: 0.00041958 -rank: [2, 5, 14, 27, 37]
Step 2801/10000 - loss: 0.00046538 -rank: [2, 5, 14, 28, 37]
Step 2901/10000 - loss: 0.00028672 -rank: [2, 5, 13, 28, 37]
Step 3001/10000 - loss: 0.00060886 -rank: [2, 5, 13, 28, 37]
Step 3101/10000 - loss: 0.00134927 -rank: [2, 5, 13, 28, 37]
Step 3201/10000 - loss: 0.00028794 -rank: [2, 5, 13, 28, 37]
Step 3301/10000 - loss: 0.00095870 -rank: [2, 5, 13, 28, 36]
Step 3401/10000 - loss: 0.00040774 -rank: [2, 5, 12, 27, 36]
Step 3501/10000 - loss: 0.00082820 -rank: [2, 5, 12, 27, 36]
Step 3601/10000 - loss: 0.00096348 -rank: [2, 5, 12, 27, 36]
Step 3701/10000 - loss: 0.00032231 -rank: [2, 5, 12, 27, 36]
Step 3801/10000 - loss: 0.00246569 -rank: [2, 5, 12, 27, 36]
Step 3901/10000 - loss: 0.00080675 -rank: [2, 5, 12, 27, 36]
Step 4001/10000 - loss: 0.00020188 -rank: [2, 5, 12, 27, 36]
Step 4101/10000 - loss: 0.00145821 -rank: [2, 5, 12, 27, 37]
Step 4201/10000 - loss: 0.00024367 -rank: [2, 5, 12, 27, 37]
Step 4301/10000 - loss: 0.00136522 -rank: [2, 5, 12, 27, 37]
Step 4401/10000 - loss: 0.00039393 -rank: [2, 5, 12, 27, 37]
Step 4501/10000 - loss: 0.00095229 -rank: [2, 5, 12, 27, 37]
Step 4601/10000 - loss: 0.00104935 -rank: [2, 5, 12, 27, 37]
Step 4701/10000 - loss: 0.00015230 -rank: [2, 5, 12, 27, 37]
Step 4801/10000 - loss: 0.00024698 -rank: [2, 5, 12, 27, 37]
Step 4901/10000 - loss: 0.00225821 -rank: [2, 5, 12, 27, 37]
Step 5001/10000 - loss: 0.00145753 -rank: [2, 5, 12, 27, 37]
Step 5101/10000 - loss: 0.00105265 -rank: [2, 5, 12, 27, 36]
Step 5201/10000 - loss: 0.00025455 -rank: [2, 5, 12, 27, 37]
Step 5301/10000 - loss: 0.00303307 -rank: [2, 5, 12, 27, 36]
Step 5401/10000 - loss: 0.00015262 -rank: [2, 5, 12, 27, 36]
Step 5501/10000 - loss: 0.00044800 -rank: [2, 5, 12, 27, 36]
Step 5601/10000 - loss: 0.00115216 -rank: [2, 5, 12, 27, 36]
Step 5701/10000 - loss: 0.00320677 -rank: [2, 5, 12, 27, 36]
Step 5801/10000 - loss: 0.00064967 -rank: [2, 5, 12, 27, 36]
Step 5901/10000 - loss: 0.00033682 -rank: [2, 5, 12, 27, 36]
Step 6001/10000 - loss: 0.00115464 -rank: [2, 5, 12, 27, 36]
Step 6101/10000 - loss: 0.00026438 -rank: [2, 5, 12, 27, 36]
Step 6201/10000 - loss: 0.00042031 -rank: [2, 5, 11, 27, 36]
Step 6301/10000 - loss: 0.00183880 -rank: [2, 5, 11, 26, 36]
Step 6401/10000 - loss: 0.00020251 -rank: [2, 5, 11, 27, 36]
Step 6501/10000 - loss: 0.00101113 -rank: [2, 5, 11, 27, 36]
Step 6601/10000 - loss: 0.00209338 -rank: [2, 5, 11, 27, 36]
Step 6701/10000 - loss: 0.00074171 -rank: [2, 5, 11, 27, 36]
Step 6801/10000 - loss: 0.00072073 -rank: [2, 5, 11, 27, 36]
Step 6901/10000 - loss: 0.00208780 -rank: [2, 5, 11, 27, 36]
Step 7001/10000 - loss: 0.00125297 -rank: [2, 5, 11, 27, 36]
Step 7101/10000 - loss: 0.00133982 -rank: [2, 5, 11, 26, 36]
Step 7201/10000 - loss: 0.00032520 -rank: [2, 5, 11, 26, 36]
Step 7301/10000 - loss: 0.00028769 -rank: [2, 5, 11, 26, 36]
Step 7401/10000 - loss: 0.00790648 -rank: [2, 5, 11, 26, 36]
Step 7501/10000 - loss: 0.00280497 -rank: [2, 5, 11, 26, 36]
Step 7601/10000 - loss: 0.00143415 -rank: [2, 5, 11, 26, 36]
Step 7701/10000 - loss: 0.00122475 -rank: [2, 5, 11, 26, 36]
Step 7801/10000 - loss: 0.00039039 -rank: [2, 5, 11, 26, 36]
Step 7901/10000 - loss: 0.00037635 -rank: [2, 5, 11, 26, 36]
Step 8001/10000 - loss: 0.00033464 -rank: [2, 5, 11, 26, 36]
Step 8101/10000 - loss: 0.00280973 -rank: [2, 5, 11, 26, 36]
Step 8201/10000 - loss: 0.00047049 -rank: [2, 5, 11, 26, 36]
Step 8301/10000 - loss: 0.00016545 -rank: [2, 5, 11, 26, 36]
Step 8401/10000 - loss: 0.00274952 -rank: [2, 5, 11, 26, 36]
Step 8501/10000 - loss: 0.00065673 -rank: [2, 5, 11, 26, 36]
Step 8601/10000 - loss: 0.00049987 -rank: [2, 5, 11, 26, 36]
Step 8701/10000 - loss: 0.00010871 -rank: [2, 5, 11, 26, 36]
Step 8801/10000 - loss: 0.00042401 -rank: [2, 5, 11, 26, 36]
Step 8901/10000 - loss: 0.00116140 -rank: [2, 5, 11, 26, 36]
Step 9001/10000 - loss: 0.00072342 -rank: [2, 5, 10, 26, 37]
Step 9101/10000 - loss: 0.00028763 -rank: [2, 5, 10, 26, 37]
Step 9201/10000 - loss: 0.00025763 -rank: [2, 5, 10, 26, 37]
Step 9301/10000 - loss: 0.00076165 -rank: [2, 5, 10, 26, 37]
Step 9401/10000 - loss: 0.00033013 -rank: [2, 5, 10, 26, 37]
Step 9501/10000 - loss: 0.00097763 -rank: [2, 5, 10, 26, 37]
Step 9601/10000 - loss: 0.00014953 -rank: [2, 5, 10, 26, 37]
Step 9701/10000 - loss: 0.00154820 -rank: [2, 5, 10, 26, 37]
Step 9801/10000 - loss: 0.00168203 -rank: [2, 5, 10, 26, 37]
Step 9901/10000 - loss: 0.00027637 -rank: [2, 5, 10, 26, 37]
Step 10000/10000 - loss: 0.00026775 -rank: [2, 5, 10, 26, 37]
MLP_Model Evaluation Results - loss: 0.00017760
